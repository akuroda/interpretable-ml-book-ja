```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
library(anchors)
```

<!--{pagebreak}-->

<!--## Scoped Rules (Anchors) {#anchors}-->
## Scoped Rules (Anchors) {#anchors}

<!--*Authors: Tobias Goerke & Magdalena Lang*-->
*著者: Tobias Goerke & Magdalena Lang*

`r if(is.html){only.in.html}`

<!--
Anchors explains individual predictions of any black-box classification model by finding a decision rule that "anchors" the prediction sufficiently.
A rule anchors a prediction if changes in other feature values do not affect the prediction.
Anchors utilizes reinforcement learning techniques in combination with a graph search algorithm to reduce the number of model calls (and hence the required runtime) to a minimum while still being able to recover from local optima. Ribeiro, Singh, and Guestrin proposed the algorithm in 2018[^Ribeiro2018Anchors] -- the same researchers that introduced the [LIME](#lime) algorithm.
-->
Anchor は、予測を "固定" するのに十分な決定規則を見つけることにより、ブラックボックスの分類モデルの個々の予測結果を説明します。
他の特徴量の値が変わっても予測に影響がない場合、ルールにより予測は固定されます。
Anchor は、強化学習とグラフ探索アルゴリズムを組み合わせて、モデルの呼び出し回数を最小限に抑えながら（これにより実行時間も抑えられます）、局所最適解に陥るのを回避できます。
このアルゴリズムは、2018年に Ribeiro、Singh、Guestrinら[^Ribeiro2018Anchors]により提案されました ([LIME](#lime)アルゴリズムを導入したのも彼らです)。

<!--Like its predecessor, the anchors approach deploys a *perturbation-based* strategy to generate *local* explanations for predictions of black-box machine learning models. 
However, instead of surrogate models used by LIME, the resulting explanations are expressed as easy-to-understand *IF-THEN* rules, called *anchors*. 
These rules are reusable since they are *scoped*: anchors include the notion of coverage, stating precisely to which other, possibly unseen, instances they apply.
Finding anchors involves an exploration or multi-armed bandit problem, which originates in the discipline of reinforcement learning.
To this end, neighbors, or perturbations, are created and evaluated for every instance that is being explained.
Doing so allows the approach to disregard the black-box’s structure and its internal parameters so that these can remain both unobserved and unaltered.
Thus, the algorithm is *model-agnostic*, meaning it can be applied to **any** class of model.-->

LIME と同様に、Anchor は、ブラックボックスな機械学習モデルの予測に対して *局所的な* 説明をするためにデータに *摂動* を与える方法を採用しています。
ただし、LIME が説明のためにサロゲートモデルを用いるのに対し、Anchor では *Anchor* と呼ばれる、より理解しやすい *IF-THEN* ルールが用いられます。
これらのルールはスコープ化されているので再利用が可能です。つまり、Anchor はカバレッジの概念が含まれており、それが他のインスタンス、もしくはまだ見ぬインスタンスに適用されるかを正確に示しています。
Anchor を見つけることは、強化学習の分野に由来する探索または多腕バンディット問題を伴います。
そのため、説明される各インスタンスに対して、近傍データ（摂動）を作成し、評価する必要があります。
そうすることで、ブラックボックスの構造とその内部パラメータを無視するアプローチが可能になり、これらが参照されず、変更されないままになります。
したがって、このアルゴリズムは *モデル非依存* であり、**任意の** クラスのモデルに適用できます。

<!--
In their paper, the authors compare both of their algorithms and visualize how differently these consult an instance's neighborhood to derive results.
For this, the following figure depicts both LIME and anchors locally explaining a complex binary classifier (predicts either **-** or **+**) using two exemplary instances.
LIME’s results do not indicate how faithful they are as LIME solely learns a linear decision boundary that best approximates the model given a perturbation space $D$.
Given the same perturbation space, the anchors approach constructs explanations whose coverage is adapted to the model’s behavior and clearly express their boundaries.
Thus, they are faithful by design and state exactly for which instances they are valid.
This property makes anchors particularly intuitive and easy to comprehend.
-->
彼らの論文では、LIME と Anchor の両方のアルゴリズムを比較し、結果を導出するためにインスタンスの近傍を参照する方法がどのように異なるかを視覚化しています。
次の図は、2つのインスタンスを使用して、LIME と Anchor の両方が複雑な2値分類モデル（**-** または **+** のいずれかを予測）を局所的に説明している様子を示しています。
LIMEは、摂動空間 $D$ が与えられたモデルを局所的に最もよく近似する線形決定境界を学習するだけなので、LIMEの結果がどれだけ忠実であるかを示すものではありません。
同じ摂動空間を与えられると、Anchor は、モデルの振る舞いに適応したカバレッジを持つ説明を構築し、その境界を明確に表現します。
したがって、Anchor は設計上忠実であり、どのインスタンスに対して有効であるかを正確に示します。
この特性により、Anchor は特に直感的で理解しやすくなります。

<!--fig.cap="LIME vs. Anchors -- A Toy Visualization. Figure from Ribeiro, Singh, and Guestrin (2018)."-->

```{r fig.cap="LIME vs. Anchor -- 簡単な可視化。図はRibeiro, Singh, and Guestrin (2018)より", out.width=350, fig.align="center"}
knitr::include_graphics("images/anchors-visualization.png")
```

<!--As mentioned before, the algorithm’s results or explanations come in the form of rules, called anchors.
The following simple example illustrates such an anchor.
For instance, suppose we are given a bivariate black-box model that predicts whether or not a passenger survives the Titanic disaster.
Now we would like to know *why* the model predicts for one specific individual that it survives.
The anchors algorithm provides a result explanation like the one shown below.-->
前述したように、アルゴリズムの結果や説明は、Anchor と呼ばれるルールの形で得られます。
例えば、タイタニック号の事故で乗客が生き残るかどうかを予測する二変量のブラックボックスモデルが与えられたとします。
ここで私たちは、モデルがある特定の個人の生存を予測している *理由* を知りたいと思います。
Anchor アルゴリズムは、以下に示すような説明を提供します。

<!--Table: one exemplary individual and the model's prediction-->
表 ある個人とモデルの予測の例。

| Feature         | Value         |
| --------------- |:-------------:|
| Age             | 20            |
| Sex             | female        |
| Class           | first         |
| TicketPrice     | 300\$          |
| More attributes | ...           |
| **Survived**    | **true**      |


<!--And the corresponding anchors explanation is:-->
そして、対応するAnchorsの説明は以下のようになります。

IF `SEX = female`  
AND `Class = first`  
THEN PREDICT `Survived = true`  
WITH PRECISION `97%`  
AND COVERAGE `15%`  
 
<!--The example shows how anchors can provide essential insights into a model's prediction and its underlying reasoning.
The result shows which attributes were taken into account by the model, which in this case, is the female sex and first class.
Humans, being paramount for correctness, can use this rule to validate the model's behavior.
The anchor additionally tells us that it applies to 15\% of perturbation space's instances.
In those cases the explanation is 97\% accurate, meaning the displayed predicates are almost exclusively responsible for the predicted outcome.-->

この例は、Anchor がモデルの予測についての本質的な洞察とその基礎となる根拠を提供できることを示しています。
結果は、モデルがどの属性を考慮に入れたかを示しており、この例では女性でありファーストクラスであることが考慮されていました。
人は正確さを最優先するため、このルールを使ってモデルの振る舞いを検証できます。
Anchor によると、このルールは摂動空間のインスタンスの 15% に適用できます。
その場合の説明は 97％ の確率で正確であり、表示された述部が予測された結果のほぼ唯一の原因であることを意味しています。

<!--An anchor $A$ is formally defined as follows:-->

Anchor $A$ は正式には次のように定義されます。

$$\mathbb{E}_{\mathcal{D}_x(z|A)}[1_{f(x)=f(z)}]\geq\tau,A(x)=1$$

<!--Wherein:

+ $x$ represents the instance being explained (e.g., one row in a tabular data set).
+ $A$ is a set of predicates, i.e., the resulting rule or anchor, such that $A(x)=1$ when all feature predicates defined by $A$ correspond to $x$’s feature values.
+ $f$ denotes the classification model to be explained (e.g., an artificial neural network model). It can be queried to predict a label for $x$ and its perturbations.
+ $D_x (\cdot|A)$ indicates the distribution of neighbors of $x$, matching $A$.
+ $0 \leq \tau \leq 1$ specifies a precision threshold. Only rules that achieve a local fidelity of at least $\tau$ are considered a valid result.-->

+ $x$ は説明されるインスタンス（例えば、表形式のデータセットの1行）を表します。
+ $A$ は述部の集合、すなわち結果のルールまたは Anchor を示します。すべての $x$ の特徴量の値が $A$ によって定義された特徴量の述部に対応するとき、$A(x)=1$ となります。
+ $f$ は、説明する分類モデル（例えば、ニューラルネットワークモデル）を表します。これは、$x$ とその摂動に対するラベルを予測できる必要があります。
+ $D_x　(\cdot|A)$ は、$A$ に一致する $x$ の近傍データの分布を示しています。
+ $0 \leq \tau \leq 1$ は精度の閾値を指定します。少なくとも $\tau$ 以上の局所的な忠実性 (local fidelity)を達成したルールのみが有効な結果とみなされます。


<!--The formal description may be intimidating and can be put in words:-->
形式的な説明は威圧的かもしれないので、言葉にしてみましょう。

<!--Given an instance $x$ to be explained, a rule or an anchor $A$ is to be found, such that it applies to $x$, while the same class as for $x$ gets predicted for a fraction of at least $\tau$ of $x$’s neighbors where the same $A$ is applicable. A rule’s precision results from evaluating neighbors or perturbations (following $D_x (z|A)$) using the provided machine learning model (denoted by the indicator function $1_{f(x) = f(z)}$).-->

説明されるインスタンス $x$ が与えられると、$x$ に適用されるようなルールまたは Anchor $A$ を見つけます。このとき、同じ $A$ を適用できる $x$ の近傍データのうち、少なくとも $\tau$ の割合
については $x$ と同じクラスであると予測されるようにします。ルールの精度は、与えられた機械学習モデル（指標関数 $1_{f(x) = f(z)}$ で示される）を用いて、近傍データまたは摂動（$D_x (z|A)$ に続く）を評価することで得られます。

<!--### Finding Anchors-->

### Anchor の発見

<!--Although anchors’ mathematical description may seem clear and straightforward, constructing particular rules is infeasible.
It would require evaluating $1_{f(x) = f(z)}$ for all $z \in \mathcal{D}_x(\cdot|A)$ which is not possible in continuous or large input spaces.
Therefore, the authors propose to introduce the parameter $0 \leq \delta \leq 1$ to create a probabilistic definition.
This way, samples are drawn until there is statistical confidence concerning their precision.
The probabilistic definition reads as follows:-->

Anchor の数学的な説明は明確で分かりやすいように見えますが、特定のルールを作成することは実行不可能です。
すべての連続空間や大規模な入力空間では不可能な $z \in \mathcal{D}_x(\cdot|A)$ で $1_{f(x) = f(z)}$ を評価する必要があります。
それゆえ、著者らは $0 \leq \delta \leq 1$ のパラメータを使用して、確率的な定義をします。
このようにして、サンプルは統計的に信頼のある精度が出るまで引き出されます。
確率的な定義は以下のようになります。

$$P(prec(A)\geq\tau)\geq{}1-\delta\quad\textrm{with}\quad{}prec(A)=\mathbb{E}_{\mathcal{D}_x(z|A)}[1_{f(x)=f(z)}]$$

<!--The previous two definitions are combined and extended by the notion of coverage.
Its rationale consists of finding rules that apply to a preferably large part of the model’s input space.
Coverage is formally defined as an anchors' probability of applying to its neighbors, i.e., its perturbation space: -->

前述の2つの概念はカバレッジの概念により結合・拡張されます。
その理論的根拠はモデルの入力空間の大部分に適用できるルールを見つけることから構成されます。
カバレッジは近傍(摂動空間)に適応できる Anchor の確率として定義されます。

$$cov(A)=\mathbb{E}_{\mathcal{D}_{(z)}[A(z)]}$$ 

<!--Including this element leads to anchors' final definition taking into account the maximization of coverage:-->

この要素を含めるとカバレッジ最大化を考慮できる Anchor の最終的な定義が可能となります。

$$\underset{A\:\textrm{s.t.}\;P(prec(A)\geq\tau)\geq{}1-\delta}{\textrm{max}}cov(A)$$

<!--Thus, the proceeding strives for a rule that has the highest coverage among all eligible rules (all those that satisfy the precision threshold given the probabilistic definition).
These rules are thought to be more important, as they describe a larger part of the model.
Note that rules with more predicates tend to have higher precision than rules with fewer predicates.
In particular, a rule that fixes every feature of $x$ reduces the evaluated neighborhood to identical instances.
Thus, the model classifies all neighbors equally, and the rule’s precision is $1$.
At the same time, a rule that fixes many features is overly specific and only applicable to a few instances.
Hence, there is a *trade-off between precision and coverage*.-->
したがって、この手続きではすべての適格なルール（確率的な定義の閾値を満たす全てのルール）の中で最大のカバレッジをもつルールを目指しています。
モデルの大部分を説明するために、これらのルールはより重要なものと考えられます。
ただし、より多くのルールを持つ述部は、ルールが少ないときと比べて精度が高くなることに注意してください。
特に、$x$ のそれぞれの特徴量を固定するようなルールは、評価する近傍を同一のインスタンスのみに減らします。
それゆえ、モデルは全ての近傍を同様に分類し、規則の精度は $1$ になります。
同時に、多くの特徴を固定するルールは、特定のしすぎであり、少数のインスタンスにしか適用できません。
それゆえ、 *精度とカバレッジにはトレードオフ* があります。

<!--The anchors approach uses four main components to find explanations, as is shown in the figure below.-->

Anchor のアプローチは説明を見つけるため、下図のように、4つの要素を使用します。

<!--**Candidate Generation**: Generates new explanation candidates.
In the first round, one candidate per feature of $x$ gets created and fixes the respective value of possible perturbations.
In every other round, the best candidates of the previous round are extended by one feature predicate that is not yet contained therein.-->

**候補の生成**: 説明の候補を生成します。
最初の段階では、$x$ のそれぞれの特徴量に対して1つの候補が作成され、可能な摂動の値でそれぞれの値を固定します。
その他の段階では、前の段階での最良な候補に、まだ含まれていない述語を1つ追加することで拡張されます。

<!--**Best Candidate Identification**: Candidate rules are to be compared in regard to which rule explains $x$ the best.
To this end, perturbations that match the currently observed rule are created evaluated by calling the model.
However, these calls need to be minimized as to limit computational overhead.
This is why, at the core of this component, there is a pure-exploration Multi-Armed-Bandit (*MAB*; *KL-LUCB*[^KLLUCB], to be precise).
MABs are used to efficiently explore and exploit different strategies (called arms in an analogy to slot machines) using sequential selection.
In the given setting, each candidate rule is to be seen as an arm that can be pulled. Each time it is pulled, respective neighbors get evaluated, and we thereby obtain more information about the candidate rule's payoff (precision in anchors' case).
The precision thus states how well the rule describes the instance to be explained.-->
**最良の候補の特定**: 候補となるルールのうち、どのルールが $x$ を最も説明できているか比較できる必要があります。
この目的を達成するために、現在観測されているルールに合う摂動が作成され、モデルを呼び出すことで評価されます。
しかしながら、これらの呼び出しは計算負荷を少なくするために最小限にする必要があります。
そのため、この要素の中核には純粋な探索問題 Multi-Armed-Bandit（*MAB*; 正確には *KL-LUCB*[^KLLUCB]）があります。
MAB は逐次選択を使用して、様々な戦略 (スロットマシーンに倣ってアームと呼ばれる) を効率的に探索するために使用されます。
与えられたルールの中では、それぞれの候補となるルールはアームに見立てられます。
アームが引っ張られるたびに、それぞれの近傍が評価され、候補のルールの報酬についてより多くの情報（Anchor の場合の精度）を得ることができます。
精度はルールがどの程度インスタンスを説明できているかを示します。

<!--**Candidate Precision Validation**: Takes more samples in case there is no statistical confidence yet that the candidate exceeds the $\tau$ threshold.-->

**候補の精度検証**: 候補の精度が閾値 $\tau$ を超えているかどうか統計的に信頼性がない時はさらに多くのサンプルを取ります。

<!--**Modified Beam Search**: All of the above components are assembled in a beam search, which is a graph search algorithm and a variant of the breadth-first algorithm.
It carries the $B$ best candidates of each round over to the next one (where $B$ is called the *Beam Width*).
These $B$ best rules are then used to create new rules. The beam search conducts at most $featureCount(x)$ rounds, as each feature can only be included in a rule at most once.
Thus, at every round $i$, it generates candidates with exactly $i$ predicates and selects the B best thereof.
Therefore, by setting $B$ high, the algorithm more likely avoids local optima.
In turn, this requires a high number of model calls and thereby increases the computational load.-->

**修正されたビームサーチ**: 上記全ての要素はグラフ探索アルゴリズムで幅優先アルゴリズムの派生であるビームサーチによって組み立てられます。
ビームサーチは各ラウンドの $B$ 個の最良の候補を次のラウンドに運びます ($B$ は *ビーム幅* と呼ばれます)。
これらの $B$ 個の最良のルールは次の新しいルールを作るために使用されます。
ビームサーチは各特徴量が含まれるのは1回だけなので最大で $featureCount(x)$ 回行います。
それゆえ、それぞれのラウンド $i$ で、それぞれ $i$ 個の述語をもつ候補を生成してその中で最良の $B$ 個を選択します。
したがって、$B$ を高く設定するとアルゴリズムは局所最適解を回避しやすくなります。
一方で、モデルの呼び出し回数は多くなるため、計算負荷が増加します。

<!--
fig.cap="The anchors algorithm’s components and their interrelations (simplified)"
-->

```{r fig.cap="Anchor アルゴリズムの構成要素とその相互関係（簡易版）", out.width=800}
knitr::include_graphics("images/anchors-process.jpg")
```

<!--The approach is a seemingly perfect recipe for efficiently deriving statistically sound information about why any system classified an instance the way it did.
It systematically experiments with the model’s input and concludes by observing respective outputs.
It relies on well established and researched Machine Learning methods (MABs) to reduce the number of calls made to the model.
This, in turn, drastically reduces the algorithm’s runtime.-->
このアプローチは一見すると、どのようなシステムでもインスタンスを分類した理由について、統計的に健全な情報を効率的に導き出すことができる完璧なレシピのように見えます。
このアプローチは、モデルの入力を機械的に実験し、それぞれの出力を観察することで結論づけます。
モデルの呼び出し回数を削減するために、研究・確立された機械学習の手法（MAB）に依存します。
これによりアルゴリズムの時間を短縮できます。

<!--### Complexity and Runtime-->

### 複雑性と実行時間

<!--Knowing the anchors approach’s asymptotic runtime behavior helps to evaluate how well it is expected to perform on specific problems.
Let $B$ denote the beam width and $p$ the number of all features. Then the anchors algorithm is subject to:-->

Anchor アプローチの漸近的な実行時間のふるまいを知ることは、特定の問題に対してどのくらい良いパフォーマンスが期待されるかを評価することに役立ちます。
$B$ はビーム幅、$p$ は特徴量の数とします。
すると、Anchor アルゴリズムは次のようになります。

$$\mathcal{O}(B\cdot{}p^2+p^2\cdot\mathcal{O}_{\textrm{MAB}\lbrack{}B\cdot{}p,B\rbrack})$$

<!--This boundary abstracts from problem-independent hyperparameters, such as the statistical confidence $\delta$.
Ignoring hyperparameters helps reduce the boundary's complexity (see original paper for more info).
Since the MAB extracts the $B$ best out of $B \cdot p$ candidates in each round, most MABs and their runtimes multiply the $p^2$ factor more than any other parameter.-->

この境界は統計的な信頼度 $\delta$ のような、問題に依存しないハイパーパラメータを抽象化したものです。
ハイパーパラメータを無視することで、境界の複雑さを軽減できます (詳細は元の論文を参照してください)。
MABは各ラウンドで $B \cdot p$ の中から最良の候補 $B$ を取り出すので、ほとんどのMABとその実行時間は、他のパラメータに係数 $p^2$ がかけられます。

<!--It thus becomes apparent: the algorithm’s efficiency decreases with feature abundant problems.-->

ですからこれは明らかなことですが、特徴量が大きくなると、アルゴリズムの効率は低下します。

<!--### Tabular Data Example-->
### 表形式データの例

<!--Tabular data is structured data represented by tables, wherein columns embody features and rows instances. 
For instance, we use the [bike rental data](#bike-data) to demonstrate the anchors approach's potential to explain ML predictions for selected instances.
For this, we turn the regression into a classification problem and train a random forest as our black-box model.
It is to classify whether the number of rented bicycles lies above or below the trend line. -->

表形式のデータは表によってあらわされた構造化データで、列は特徴量を表し、行はインスタンスを表しています。
Anchor アプローチのポテンシャルを示すために、例として、[レンタル自転車のデータ](#bike-data)を使って、選択されたインスタンスの機械学習の予測の説明をしてみましょう。
ここでは、回帰ではなく分類問題として扱い、ブラックボックスモデルとしてランダムフォレストで学習しています。
レンタル自転車の数がトレンド曲線よりも上にあるか下にあるかを分類しています。

<!--Before creating anchor explanations, one needs to define a perturbation function. 
An easy way to do so is to use an intuitive default perturbation space for tabular explanation cases which can be built by sampling from, e.g., the training data. 
When perturbing an instance, this default approach maintains the features' values that are subject to the anchors' predicates, while replacing the non-fixed features with values taken from another randomly sampled instance with a specified probability. 
This process yields new instances that are similar to the explained one but have adopted some values from other random instances.
Thus, they resemble neighbors.-->

Anchor による説明を生成する前に、摂動関数を定義する必要があります。
簡単な方法としては、例えば学習データからサンプリングして作られた直感的な摂動空間を用いることです。
インスタンスを摂動させるとき、このデフォルトのアプローチでは、Anchor の述語の対象となる特徴量の値を維持し、固定されていない特徴量を、特定の確率でランダムにサンプリングされた別のインスタンスの値で置き換えます。
このプロセスでは、説明されるインスタンスと似ているが、他のランダムなインスタンスの値もいくつかもつような新たなインスタンスを生成します。
このようなインスタンスは、近傍と言えます。

```{r results='hide', cache=FALSE}
library(anchors)
library(jsonlite)
library(BBmisc)
library(uuid)
library(magrittr)
set.seed(1)

colPal = c("#555555","#DFAD47","#7EBCA9", "#E5344E", "#681885", "#d25d97", "#fd3c46", "#ff9a39", "#6893bf", "#42c3a8")
load("../data/bike.RData")

bike$target = factor(resid(lm(cnt ~ days_since_2011, data = bike)) > 0, 
                     levels = c(FALSE, TRUE), labels = c('below', 'above'))
bike$cnt = NULL
# Make long factor levels shorter
levels(bike$weathersit)[levels(bike$weathersit)=="RAIN/SNOW/STORM"] <- "BAD"


bike.task = makeClassifTask(data = bike, target = "target")
```

```{r results='hide',  eval = FALSE}
# If you want to update anchors, make sure to set eval=TRUE and add the RDS files to the repository
devtools::install_github("viadee/anchorsOnR")
library(anchors)
library(jsonlite)
library(BBmisc)
library(uuid)
library(magrittr)
set.seed(1)


mod = mlr::train(mlr::makeLearner(cl = 'classif.randomForest', 
                                  id = 'bike-rf'), bike.task)
bikeDisc = list(
  integer(),
  integer(),
  integer(),
  integer(),
  integer(),
  integer(),
  integer(),
  c(0, 7, 14, 21, 28),
  c(30, 60, 69, 92),
  c(5, 10, 15, 20, 25),
  integer()
)

bike.explainer = anchors(bike, mod, target = "target", bins = bikeDisc, tau = 0.9, batchSize = 1000, beams = 1)
bike.explained.instances = bike[c(40, 475, 610, 106, 200, 700),] 
bike.explanations = anchors::explain(bike.explained.instances, bike.explainer)
saveRDS(bike.explanations, file = "../data/cached-anchors.RDS")

bike.explainer_edge = anchors(bike, mod, target = "target", tau = 1, batchSize = 1000, beams = 1, allowSuboptimalSteps = F)
bike.explained.instances_edge = bike[c(452, 300),] 
bike.explanations_edge = anchors::explain(bike.explained.instances_edge, bike.explainer_edge)
saveRDS(bike.explanations_edge, file = "../data/cached-anchors-edge.RDS")
```

<!--fig.cap="Anchors explaining six instances of the bike rental dataset. Each row represents one explanation or anchor, and each bar depicts the feature predicates contained by it. The x-axis displays a rule's precision, and a bar's thickness corresponds to its coverage. The 'base' rule contains no predicates. These anchors show that the model mainly considers the temperature for predictions."-->

```{r message=FALSE, cache=TRUE, fig.cap="レンタル自転車のデータセットの6つのインスタンスを説明する Anchor。各列は1つの説明もしくはAnchor、各バーはそれに含まれた特徴量の述部を表している。x軸はルールの精度を表し、バーの厚みは範囲に対応している。'base' ルールは述部を含んでない。これらの Anchor によってモデルは予測の際に主に温度を考慮に入れていることが示されている。", fig.height=10, fig.width=10}
bike.explanations = readRDS("../data/cached-anchors.RDS")
plotExplanations(bike.explanations, colPal = colPal)
```

<!--The results are instinctively interpretable and show for each explained instance, which features are most important for the model's prediction.
As the anchors only have a few predicates, they additionally have high coverage and hence apply to other cases.
The rules shown above were generated with $\tau = 0.9$.
Thus, we ask for anchors whose evaluated perturbations faithfully support the label with an accuracy of at least $90\%$.
Also, discretization was used to increase the expressiveness and applicability of numerical features. -->

この結果は直感的に解釈できるもので、モデルの予測に関してどの特徴量が最も重要であるかがそれぞれのインスタンスについて示されています。
さらに、Anchorは少ない述部しか持たないので、広い範囲をカバーし他のケースにも適用できます。
上に示されるルールは $\tau = 0.9$ で作成されました。
つまり、評価された摂動が $90\%$ の精度でラベルを忠実にサポートするような Anchor が求められます。
また、量的特徴量の表現力や適応性を上げるために離散化も行っています。

<!--All of the previous rules were generated for instances where the model decides confidently based on a few features.
However, other instances are not as distinctly classified by the model as more features are of importance.
In such cases, anchors get more specific, comprise more features, and apply to fewer instances.-->

これまでのすべてのルールは、モデルが少ない特徴量に基づいて自信を持って決定できるインスタンスに対して
作られました。
しかし、他のインスタンスはより多くの特徴量が重要であるため、モデルによって明確に分類されていません。
そのような場合には、Anchor はより具体的になり、より多くの特徴量を持ち、より少ないインスタンスにのみ適用されます。

<!--fig.cap="Explaining instances near decision boundaries leads to specific rules comprising a higher number of feature predicates and lower coverage. Also, the empty rule, i.e., the base feature, gets less important. This can be interpreted as a signal for a decision boundary, as the instance is located in a volatile neighborhood."-->

```{r message=FALSE, warning=FALSE, echo=FALSE, results='hide', cache=TRUE, fig.cap="決定境界周辺のインスタンスを説明するには、より多くの特徴量の述部とより低いカバレッジからなる特殊なルールが必要。空のルール、すなわち基本特徴量は重要性が低くなる。これは、インスタンスが不安定な近傍の中に位置するので、決定境界のシグナルとして解釈できる。", fig.height=9, fig.width=10}
bike.explanations_edge = readRDS("../data/cached-anchors-edge.RDS")
plotExplanations(bike.explanations_edge, colPal = colPal)
```

<!--While choosing the default perturbation space is a comfortable choice to make, it may have a great impact on the algorithm and can thus lead to biased results.
For example, if the train set is unbalanced (there is an unequal number of instances of each class), the perturbation space is as well.
This condition further affects the rule-finding and the result's precision.-->

デフォルトの摂動空間を選ぶことは適した選択ですが、一方でアルゴリズムに大きな影響を与え、結果が偏ってしまう可能性もあります。
例えば、学習データが不均衡である（それぞれのクラスのインスタンスの数が均等でない）とき、摂動空間も同様になります。
さらにこの状況はルールの発見や結果の精度にも影響します。

<!--The [cervical cancer](#cervical) data set is an excellent example of this situation Applying the anchors algorithm leads to one of the following situations: -->
[子宮頸がん](#cervical)のデータセットは Anchor アルゴリズムが以下のような状況につながる典型的な例です。

<!--
+ Explaining instances labeled *healthy* yields empty rules as all generated neighbors evaluate to *healthy*.
+ Explanations for instances labeled *cancer* are overly specific, i.e., comprise many feature predicates, since the perturbation space mostly covers values from *healthy* instances.
-->

+ *healthy* とラベル付けされたインスタンスはすべての近傍が *healthy* と評価されるので空のルールが作り出されます。
+ 摂動空間はほとんどが *healthy* データの値でカバーされているため、*cancer* とラベル付けされたインスタンスに対する説明は過度に具体的であり、述部は多くの特徴量を持っています。

```{r}
load("../data/cervical.RData")
cervical.sampled.healthy <- cervical[sample(which(cervical$Biopsy == "Healthy"), 20), ]
cervical.balanced <- rbind(cervical[cervical$Biopsy == "Cancer", ], cervical.sampled.healthy)
```

```{r message=FALSE, warning=FALSE, echo=FALSE, results='hide',  eval = FALSE}
set.seed(1)

cervical.task = makeClassifTask(data = cervical, target = "Biopsy")
mod = mlr::train(mlr::makeLearner(cl = 'classif.randomForest', id = 'cervical-rf', 
                                  predict.type = 'prob'), cervical.task)
cancer.explainer = anchors(cervical, mod, beams = 1)
cancer.explanation = anchors::explain(cervical[c(1,7),], cancer.explainer)
saveRDS(cancer.explanation, file = "../data/cached-anchors-cervical.RDS")


set.seed(1)
cancer.explainer.balanced = anchors(cervical.balanced, mod, tau = 1, beams = 2,
                                    delta = 0.05, epsilon = 0.05, batchSize = 1000,
                                    emptyRuleEvaluations = 1000)
cancer.explanation.balanced = anchors::explain(cervical.sampled.healthy[2:5,], cancer.explainer.balanced)
saveRDS(cancer.explanation.balanced, file = "../data/cached-anchors-cervical-balanced.RDS")
```

<!--fig.cap="Constructing anchors within unbalanced perturbation spaces leads to unexpressive results."-->

```{r message=FALSE, warning=FALSE, echo=FALSE, results='hide', cache=TRUE, fig.cap="不均衡な摂動空間中で Anchor を構築すると、予期しない結果となる。", fig.height=10, fig.width=10}
cancer.explanation = readRDS("../data/cached-anchors-cervical.RDS")
plotExplanations(cancer.explanation, colPal = colPal)
```

<!--
This outcome may be unwanted and can be approached in multiple ways.
For example, a custom perturbation space can be defined that samples differently, e.g., from an unbalanced data set or a normal distribution.
This, however, comes with a side-effect: the sampled neighbors are not representative and change the coverage's scope.
Alternatively, we could modify the MAB's confidence $\delta$ and error parameter values $\epsilon$.
This would cause the MAB to draw more samples, ultimately leading to the minority being sampled more often in absolute terms.  
-->

この結果は、求めていたものとは異なるでしょうが、いくつかの方法でアプローチできます。
例えば、不均衡なデータセットや正規分布から異なるサンプリング方法で得られる別の摂動空間を定義できます。
しかし、これには副作用があります。それは、サンプリングされた近傍は代表的なものでなく、カバレッジのスコープが変わってしまいます。
あるいは、MAB の信頼度 $\delta$ と誤差パラメータの値 $\epsilon$ を修正するという方法もあります。
これによって MAB はより多くのサンプルを引き出し、最終的にマイノリティのサンプルが、よりサンプリングされやすくなります。

<!--
For this example, we use a subset of the cervical cancer set in which the majority of cases are labeled *cancer*.
We then have the framework to create a corresponding perturbation space from it.
Perturbations are now more likely to lead to varying predictions, and the anchors algorithm can identify important features.
However, one needs to take the coverage's definition into account: it is only defined within the perturbation space.
In the previous examples, we used the train set as the perturbation space's basis.
Since we only use a subset here, a high coverage does not necessarily indicate globally high rule importance. 
-->

例えば、多くのケースが *cancer* とラベル付けされているように子宮頸がんデータの一部のみを使用します。
そして、そこから対応する摂動空間を作るようなフレームワークを使用します。
摂動は、予測を変化させる可能性が高くなり、Anchor アルゴリズムは重要な特徴量を特定できるようになります。
しかし、カバレッジの定義を考慮に入れる必要があり、カバレッジは摂動空間の中でのみ定義されています。
前の例では、摂動空間の基底として学習データを用いました。
ここではデータセットの一部を用いているので、カバレッジが高いことは必ずしもグローバルにルールの重要性が高いことを示しているわけではありません。

<!--
fig.cap="Balancing the data set before constructing anchors shows the model's reasoning for decisions in minority cases."
-->

```{r message=FALSE, warning=FALSE, echo=FALSE, results='hide', cache=TRUE, fig.cap="Anchor を構築する前にデータセットを均一にすることで、マイノリティのケースにおけるモデルの判断根拠がわかる。", fig.height=10, fig.width=11}
cancer.explanation.balanced = readRDS("../data/cached-anchors-cervical-balanced.RDS")
table(cervical.balanced$Biopsy)
plotExplanations(cancer.explanation.balanced, colPal = colPal)
```

<!--
### Advantages
-->

### 長所

<!--
The anchors approach offers multiple advantages over LIME.
First, the algorithm’s output is easier to understand, as rules are **easy to interpret** (even for laypersons).
Furthermore, **anchors are subsettable** and even state a measure of importance by including the notion of coverage.
Second, the anchors approach **works when model predictions are non-linear or complex** in an instance’s neighborhood.
As the approach deploys reinforcement learning techniques instead of fitting surrogate models, it is less likely to underfit the model.
-->
Anchor のアプローチは、LIME に比べて複数の長所があります。
まず第一に、ルールが **解釈しやすい** ため（素人であっても）、アルゴリズムの出力を容易に理解できます。
さらに、**Anchor はサブセット化可能** であり、カバレッジの概念を含めることで重要度の尺度を示します。
第二に、Anchor のアプローチは入力の近傍において **モデルによる予測が非線形や複雑な場合でも機能します**。
このアプローチはサロゲートモデルをフィッティングする代わりに強化学習の手法を使用するため、モデルのアンダーフィットは起こりにくいです。

<!--
Apart from that, the algorithm is **model-agnostic** and thus applicable to any model.
Furthermore, it is **highly efficient as it can be parallelized** by making use of MABs that support batch sampling (e.g., BatchSAR).
-->
それとは別に、アルゴリズムが**モデルに依存しない**ため、どのモデルに対しても適用できます。
さらに、アルゴリズムはバッチサンプリングをサポートしているMAB（BatchSARなど）を利用することで**並列化できるので、非常に効率的です**。

<!--
### Disadvantages
-->

### 短所

<!--
The algorithm suffers from a **highly configurable** and impactful setup, just like most perturbation-based explainers.
Not only do hyperparameters such as the beam width or precision threshold need to be tuned to yield meaningful results but also does the perturbation function need to be explicitly designed for one domain/use-case.
Think of how tabular data gets perturbed and think of how to apply the same concepts to image data (Hint: these cannot be applied).
Luckily, default approaches may be used in some domains (e.g., tabular), facilitating an initial explanation setup.
-->
このアルゴリズムは、ほとんどの摂動ベースの説明手法と同様に、**高度に変更可能**で影響力のある設定に悩まされます。
意味のある結果を得るために、ビーム幅や精度の閾値などのハイパーパラメータを調整する必要があるだけでなく、摂動関数を1つのドメイン／ユースケース用に設計する必要もあります。
表形式のデータをどのように摂動させるか考えてみてください。
同様の摂動を画像データに適用するにはどうしたらいいでしょうか（ヒント: 適用できません）。
幸いなことに、一部のドメイン（表形式など）ではデフォルトのアプローチが使用され、説明の初期設定が楽になります。

<!--
Also, **many scenarios require discretization** as otherwise results are too specific, have low coverage, and do not contribute to understanding the model.
While discretization can help, it may also blur decision boundaries if used carelessly and thus have the exact opposite effect.
Since there is no best discretization technique, users need to be aware of the data before deciding on how to discretize data not to obtain poor results.
-->
また、**多くの場合では離散化が必要です**。
そうしないと、結果が具体的すぎたり、カバレッジが低すぎたり、モデルの理解に貢献しないものになってしまうからです。
離散化は役立つ場合もありますが、不用意に使用すると決定境界が曖昧になる可能性があり、全く逆の効果をもたらしてしまいます。
最良の離散化手法は存在しないため、悪い結果が得られないように、ユーザはデータの離散化手法を決定する前にデータを把握する必要があります。

<!--
Constructing anchors requires **many calls to the ML model**, just like all perturbation-based explainers.
While the algorithm deploys MABs to minimize the number of calls, its runtime still very much depends on the model’s performance and is therefore highly variable.
-->

Anchor の構築には、全ての摂動ベースの説明手法と同様に、**機械学習モデルを何度も呼び出す** 必要があります。
アルゴリズムは呼び出し回数を最小限に抑えるために MAB を使用していますが、それでも実行時間はモデルのパフォーマンスに大きく依存するため非常に変わりやすいです。

<!--
Lastly, the notion of **coverage is undefined in some domains**. 
For example, there is no obvious or universal definition of how superpixels in one image compare to such in other images.
-->
最後に、**一部のドメインではカバレッジの概念が定義されていません**。
例えば、ある画像のスーパーピクセルと他の画像のスーパーピクセルをどのように比較するのか、その明確なまたは普遍的な定義はありません。

<!--
### Software and Alternatives
-->
### ソフトウェアと代替手法

<!--
There currently are two implementations available: [anchor, a Python package](https://github.com/marcotcr/anchor) (also integrated by [Alibi](https://github.com/SeldonIO/alibi)) and a [Java implementation](https://github.com/viadee/javaAnchorExplainer).
The former is the anchors algorithm's authors' reference and the latter a high-performance implementation which comes with an R interface, called [anchors](https://github.com/viadee/anchorsOnR), which was used for the examples in this chapter.
As of now, anchors supports tabular data only. 
However, anchors may theoretically be constructed for any domain or type of data.
-->
現在、[Python パッケージの anchor](https://github.com/marcotcr/anchor)（[Alibi](https://github.com/SeldonIO/alibi)にも統合されています）と [Java implementation](https://github.com/viadee/javaAnchorExplainer) の2つの実装が利用可能です。
前者は Anchor アルゴリズムの著者のリファレンスで、後者は高い性能を示す R のインターフェイスを持つ実装であり、[anchors](https://github.com/viadee/anchorsOnR)と呼ばれています。
この章の例ではこれを用いました。
今のところ、Anchor は表形式のデータのみをサポートしています。
ただし、理論的には任意のドメインまたはデータのタイプに対しても使うことができます。

[^Ribeiro2018Anchors]: Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin. "Anchors: High-Precision Model-Agnostic Explanations." AAAI Conference on Artificial Intelligence (AAAI), 2018

[^KLLUCB]: Emilie Kaufmann and Shivaram Kalyanakrishnan. “Information Complexity in Bandit Subset Selection”. Proceedings of Machine Learning Research (2013).
